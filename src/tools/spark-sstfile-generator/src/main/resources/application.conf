{
  # Spark relation config
  spark: {
    app: {
      name: Spark Writer
    }

    driver: {
      cores: 1
      maxResultSize: 1G
    }

    cores {
      max: 16
    }
  }

  # Nebula Graph relation config
  nebula: {
    addresses: ["127.0.0.1:3699"]
    user: user
    pswd: password
    space: test

    connection {
      timeout: 3000
      retry: 3
    }

    execution {
      retry: 3
    }
  }

  # Processing tags
  tags: {

    # Loading tag from HDFS and data type is parquet
    tag-name-0: {
      type: parquet
      path: hdfs tag path 0
      fields: {
        hive-field-0: nebula-field-0,
        hive-field-1: nebula-field-1,
        hive-field-2: nebula-field-2
      }
      vertex: hive-field-0
    }

    # Loading from Hive
    tag-name-1: {
      type: hive
      # When hive table PK field's type is non-integer, use nebula provided `uuid(hive-field-0)` to generate integer type id
      # When false, `hive-field-0` must be integer type
      use_uuid: true
      # Which field is the PK
      vertex: hive-field-0
      # This is constant string-literal, case sensitive. When multiple table has duplicate PK values, id must be obtained from `uuid(`discriminator_prefix`+`hive-field-0`)`,
      # could omitted, When specified, user must use `uuid(`discriminator_prefix`+`hive-field-0`)` to get the vertex back.
      # When omitted, it is assumed that there is no duplicate PK values accross multiple tables. CAUTIONS: when this is the case, verext could be overwriten. Last Written win.
      discriminator_prefix: tag-type-name1
      exec: "select hive-field0, hive-field1, hive-field2 from database.table"
      fields: {
        hive-field-0: nebula-field-0,
        hive-field-1: nebula-field-1,
        hive-field-2: nebula-field-2
      }
<<<<<<< HEAD
      vertex: hive-field-0
      partition: 32
=======
>>>>>>> edge support src&dest prefix
    }
  }

  # Processing edges
  edges: {
    # Loading tag from HDFS and data type is parquet
    edge-name-0: {
      type: json
      path: hdfs edge path 0
      fields: {
        hive-field-0: nebula-field-0,
        hive-field-1: nebula-field-1,
        hive-field-2: nebula-field-2
      }
      source: hive-field-0
      target: hive-field-1
      ranking: hive-field-2
      partition: 32
    }
  }

  # Loading from Hive
  edge-name-1: {
    type: hive
    exec: "select hive-field0, hive-field1, hive-field2 from database.table"
    # When hive table PK field's type is non-integer, use nebula provided `uuid(hive-field-0)` and `uuid(hive-field-1)`
    # to generate source and destination vertex id respectively
    # When false, `hive-field-0` must be integer type
    use_uuid: true
    # discriminator_prefix_src & discriminator_prefix_dest are constant string-literals, case sensitive. When multiple table has duplicate PK values, edge's source id must be `uuid(`discriminator_prefix_src`+`hive-field-0`)`
    # while destination id must be `uuid(`discriminator_prefix_dest`+`hive-field-1`)`, could omitted.
    # When omitted, it is assumed that there is no duplicate PK values accross multiple tables. CAUTIONS: when this is the case, edge could be overwriten. Last Written win.
    discriminator_prefix_src: src_vertex_type_name
    discriminator_prefix_dest: dest_vertex_type_name
    source: hive-field-0
    target: hive-field-1
    fields: {
      hive-field-0: nebula-field-0,
      hive-field-1: nebula-field-1,
      hive-field-2: nebula-field-2
    }
<<<<<<< HEAD
    source: hive-field-0
    target: hive-field-1
    partition: 32
=======
>>>>>>> edge support src&dest prefix
  }
}
